version: 2.1
commands:
  setup_environment:
    description: "Setup the machine environment"
    parameters:
      sbt_version:
        type: string
        default: 1.3.5
    steps:
      - run:
          name: Setup Machine
          command: |
            sudo apt update
            sudo apt install -y curl
            sudo wget https://github.com/sbt/sbt/releases/download/v1.3.5/sbt-1.3.5.tgz
            sudo tar xzvf sbt-1.3.5.tgz -C /usr/share/
            sudo rm sbt-1.3.5.tgz
            sudo update-alternatives --install /usr/bin/sbt sbt /usr/share/sbt/bin/sbt 100
            sudo apt-get update
            sudo apt-get install -y python-pip git mysql-client-core-5.5
            sudo apt-get clean
            sudo apt-get autoclean

jobs:
  test:
    parameters:
      spark_version:
        type: string
      singlestore_image:
        type: string
    machine: true
    resource_class: large
    environment:
      SINGLESTORE_IMAGE: << parameters.singlestore_image >>
      SINGLESTORE_PORT: 5506
      SINGLESTORE_USER: root
      SINGLESTORE_DB: test
      JAVA_HOME: /usr/lib/jvm/jdk1.8.0
      CONTINUOUS_INTEGRATION: true
      SBT_OPTS: "-Xmx256M"
    steps:
      - setup_environment
      - checkout
      - run:
          name: Setup test cluster
          command: ./scripts/setup-cluster.sh
      - run:
          name: Run tests
          command: |
            export SINGLESTORE_HOST=$(docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' singlestore-integration)
            if [ << parameters.spark_version >> == '3.0.0' ]
            then
              sbt ++2.12.12 "testOnly -- -l  OnlySpark31" -Dspark.version=<< parameters.spark_version >>
            else
              sbt ++2.12.12 "testOnly -- -l  OnlySpark30" -Dspark.version=<< parameters.spark_version >>
            fi

  publish:
    machine: true
    environment:
      JAVA_HOME: /usr/lib/jvm/jdk1.8.0
      SONATYPE_USERNAME: memsql
    steps:
      - setup_environment
      - checkout
      - run:
          name: Import GPG key
          command: |
            openssl enc -d -aes-256-cbc -K ${ENCRYPTION_KEY} -iv ${ENCRYPTION_IV} -in ci/secring.asc.enc -out ci/secring.asc
            gpg --import ci/secring.asc
      - run:
          name: Publish Spark 3.0.0
          command: |
            sbt ++2.12.12 -Dspark.version=3.0.0 clean publishSigned sonatypeBundleRelease
      - run:
          name: Publish Spark 3.1.0
          command: |
            sbt ++2.12.12 -Dspark.version=3.1.0 clean publishSigned sonatypeBundleRelease
      - run:
          name: Publish Spark 3.2.0
          command: |
            sbt ++2.12.12 -Dspark.version=3.2.0 clean publishSigned sonatypeBundleRelease

workflows:
  test:
    jobs:
      - test:
          filters:
            tags:
              only: /^v.*/
            branches:
              ignore: /.*/
          matrix:
            parameters:
              spark_version:
                - 3.0.0
                - 3.1.0
                - 3.2.0
              singlestore_image:
                - memsql/cluster-in-a-box:centos-7.1.13-11ddea2a3a-3.0.0-1.9.3
                - memsql/cluster-in-a-box:centos-7.3.2-a364d4b31f-3.0.0-1.9.3
                - memsql/cluster-in-a-box:centos-7.5.8-12c73130aa-3.2.11-1.11.11
                - memsql/cluster-in-a-box:centos-7.6.5-018454f4e3-4.0.1-1.13.0
                - singlestore/cluster-in-a-box:alma-7.8.2-8c7b918527-4.0.4-1.13.6
  publish:
    jobs:
      - approve-publish:
          type: approval
          filters:
            tags:
              only: /^v.*/
            branches:
              ignore: /.*/
      - publish:
          requires:
            - approve-publish
          filters:
            tags:
              only: /^v.*/
            branches:
              ignore: /.*/
